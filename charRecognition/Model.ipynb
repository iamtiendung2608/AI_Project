{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (12, 28)\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "WEIGHT_INIT = 0.05\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MAX_HEIGHT = 28\n",
    "MAX_WIDTH = 12\n",
    "\n",
    "ALPHA_DICT = {'0' : 0, '1' : 1, '2' : 2, '3' : 3, '4' : 4, '5' : 5, '6' : 6, '7' : 7, '8' : 8, '9' : 9, '10' : 10, 'A' : 11, 'B' : 12, 'C' : 13,\n",
    "              'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'K': 19, 'L': 20, 'M': 21, 'N': 22, 'P': 23, 'R' : 24, 'S' : 25, 'T' : 26,\n",
    "              'U' : 27, 'V' : 28, 'X' : 29, 'Y' : 30, 'Z' : 31}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (28,12,3) into shape (28,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12968\\3490708272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images_from_mul_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./charTrainset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m train = np.asarray(train, dtype = np.float64, \n\u001b[0;32m     22\u001b[0m                         order ='C')\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (28,12,3) into shape (28,)"
     ]
    }
   ],
   "source": [
    "def load_images_from_mul_folder(folder):\n",
    "    images = []\n",
    "    rls = []\n",
    "    for s_folder in os.listdir(folder):\n",
    "        for filename in os.listdir(folder + \"/\" + s_folder):\n",
    "            img = cv2.imread(os.path.join(folder + \"/\" + s_folder, filename))\n",
    "            rls.append(ALPHA_DICT[s_folder])\n",
    "            if img is not None:\n",
    "                images.extend([img])\n",
    "    return images, rls\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.extend([img])\n",
    "    return images\n",
    "train, y_train = load_images_from_mul_folder('./charTrainset')\n",
    "train = np.array(train, dtype = 'object')\n",
    "train = np.asarray(train, dtype = np.float64, \n",
    "                        order ='C')\n",
    "y_train\n",
    "\n",
    "test = load_images_from_folder('greenparking2char')\n",
    "test = np.array(test, dtype = 'object')\n",
    "test = np.asarray(test, dtype = np.float64, \n",
    "                        order ='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[  0,   1,   2],\n",
      "         [  0,   0,  22],\n",
      "         [  0,   0,  68],\n",
      "         ...,\n",
      "         [  0,   1,   6],\n",
      "         [  2,   0,   3],\n",
      "         [  5,   0,   4]],\n",
      "\n",
      "        [[  0,   0,  21],\n",
      "         [  0,   0,  44],\n",
      "         [ 37,  41, 166],\n",
      "         ...,\n",
      "         [  0,   0,  38],\n",
      "         [  0,   0,  15],\n",
      "         [  3,   0,   8]],\n",
      "\n",
      "        [[  0,   0,  61],\n",
      "         [ 26,  30, 149],\n",
      "         [ 10,  19, 206],\n",
      "         ...,\n",
      "         [ 25,  22, 155],\n",
      "         [  0,   0,  41],\n",
      "         [  0,   0,  14]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  3,   0,  13],\n",
      "         [  0,   0,  32],\n",
      "         [  4,   3, 113],\n",
      "         ...,\n",
      "         [ 14,  23, 211],\n",
      "         [  9,  13, 132],\n",
      "         [  0,   0,  59]],\n",
      "\n",
      "        [[  4,   0,   6],\n",
      "         [  0,   0,  16],\n",
      "         [  0,   0,  32],\n",
      "         ...,\n",
      "         [ 31,  40, 173],\n",
      "         [  0,   0,  46],\n",
      "         [  0,   0,  22]],\n",
      "\n",
      "        [[  5,   0,   4],\n",
      "         [  2,   0,   6],\n",
      "         [  0,   0,   9],\n",
      "         ...,\n",
      "         [  0,   0,  86],\n",
      "         [  0,   0,  29],\n",
      "         [  0,   1,   3]]], dtype=uint8)\n",
      " array([[[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]],\n",
      "\n",
      "        [[255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         ...,\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255],\n",
      "         [255, 255, 255]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "test_img = []\n",
    "test_img.extend([cv2.imread('./1352_6.jpg')])\n",
    "im = cv2.imread('./t.jpg')\n",
    "test_img.extend([im])\n",
    "#test_img.append(cv2.imread('./t.jpg'))\n",
    "#test_img = np.array(test_img, dtype = 'float32')\n",
    "#cv2.imshow('sdfgs',test_img)\n",
    "#test_img[0] = np.reshape(test_img, (1, 28, 12, 3))\n",
    "test_img = np.array(test_img, dtype = 'object')\n",
    "\n",
    "print(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test images\n",
    "#print(train[0])\n",
    "def display_image(train): \n",
    "    index = np.random.randint(train.shape[0])\n",
    "    plt.figure()\n",
    "    plt.imshow(train[index])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "#display_image(train)\n",
    "#display_image(test)\n",
    "#display_image(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: (1105, 28, 12, 3)\n",
      "Each image is of size: 28 12\n"
     ]
    }
   ],
   "source": [
    "n_train = train.shape\n",
    "\n",
    "\n",
    "print (\"Number of training examples: {}\".format(n_train))\n",
    "print (\"Each image is of size: {} {}\".format(n_train[1], n_train[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG8AAADrCAYAAABn5MiuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAELUlEQVR4nO3dzW0bMRBAYTJICc457mHVfwXaHpJz3ANzEHKKxDFFjZdPeh+gky1l4wcaHnB/amutiOnb0Qeg+xkPzHhgxgMzHpjxwL6PfPPbW23v7zkHsu9bzgc/yJZ4ePve++qv0tpHvfaVOjLnnU61nc+DR/ZJta49b2aOw/Vqmn9OpbXz1e/w1yaY8cCMB2Y8MOOBDY0K+76VWpP+3Ay4+fE/Vx6Y8cCMB2Y8MOOBGQ/MeGBDc57u0981uJ8rD8x4YMYDMx6Y8cCMB/bQUeGZt22y/tyf4coDMx6Y8cCMB2Y8MOOBGQ9sKN62XWa5W69MtR77ytT7mfauTnLlgRkPzHhgxgMzHpjxwIwHNnaJVymlN/KsvJ0Xz6F5w1x0s4R750hXHpjxwIwHZjww44EZD8x4YMtc4jW7ZxaNcfHn3z+lHnW+qisPzHhgxgMzHpjxwIwHNjYqHLgnFH50C2aBzHtYz+4m9Q7tdPtLrjww44EZD8x4YMYDMx6Y8cCG5rxtKyXrWUKRaJSKprho2ybaMmq9OXJ2u8lT/16P8cCMB2Y8MOOBGQ/MeGCDT/Hqz0NH3rIx+5mzqZ/vft7rMR6Y8cCMB2Y8MOOBGQ9smUu85vfbct8/I7y8zP2812M8MOOBGQ/MeGDGAzMe2JfOeTOX9s3OYc/4eDhXHpjxwIwHZjww44EZD2yZLaHMu2E8K1cemPHAjAdmPDDjgRkPzHhgy8x5EfIcN3ta4i2uPDDjgRkPzHhgxgMzHpjxwIbibdtlZrn1irSJV6TW3NeKXHlgxgMzHpjxwIwHZjww44Etc8vGVWeplbnywIwHZjww44EZD8x4YMYDw5y3ebSDnjDe5coDMx6Y8cCMB2Y8MOOBPXRUOHJbp/s05fKZY+v/wb/iJWauPDDjgRkPzHhgxgMzHpjxwJbZEopPG5wbIrNup3EkVx6Y8cCMB2Y8MOOBGQ/MeGCDt/LYS2s15XWZ43qvwOTbiVx5YMYDMx6Y8cCMB2Y8MOOBjd3Koxw5Mk2eOfmEs54rD8x4YMYDMx6Y8cCMBzZ26t++lVLPSYeiUa48MOOBGQ/MeGDGAzMemPHAlrnEa1pwK49oQ6nWFW/W0efKAzMemPHAjAdmPDDjgRkP7KFz3sxTvCLhrTaCOe3IM/+ybhPiygMzHpjxwIwHZjww44EZDwyznzd7y8XMGfQorjww44EZD8x4YMYDMx6Y8cC+9BFsmbNW9hyXeev+3uPjTqfb73PlgRkPzHhgxgMzHpjxwDBbQs+tN+fcnhVceWDGAzMemPHAjAdmPDDjgQ3NedtWyrlzx8b4MqyRf+1hb00XbkdFP5g7/3OuPDDjgRkPzHhgxgMzHpjxwGobOGeu1vqnlPI773B0xc/W2o9rXxiKp7X4axPMeGDGAzMemPHAjAdmPDDjgRkP7C8aUOWXhRR49gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(train)\n",
    "display_image(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(object):\n",
    "    def __init__(self, trainable=True):\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.trainable = trainable\n",
    "        self.num_epochs = EPOCHS\n",
    "        # Building model\n",
    "        self._build_model()\n",
    "\n",
    "        # Input data\n",
    "        if trainable:\n",
    "            self.model.summary()\n",
    "            self.data = train\n",
    "            self.y = y_train\n",
    "\n",
    "        optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "        self.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "    def _build_model(self):\n",
    "        # CNN model\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32, (5, 5), padding='same', activation='relu', input_shape=(28, 12, 3)))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512, activation='relu'))\n",
    "        self.model.add(Dropout(0.25))\n",
    "        self.model.add(Dense(32, activation='softmax'))\n",
    "\n",
    "    def train(self):\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor='acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "        print(\"Training......\")\n",
    "        trainX = self.data\n",
    "        trainY = self.y\n",
    "        trainX = np.array(trainX)\n",
    "        trainY = np.array(trainY)\n",
    "\n",
    "        self.model.fit(datagen.flow(trainX, trainY, batch_size=self.batch_size), callbacks=[learning_rate_reduction], verbose=1,\n",
    "                       epochs=self.num_epochs, shuffle=True)\n",
    "    def predict(self):\n",
    "        testX = test\n",
    "        testX = np.array(testX)\n",
    "        testY = np.argmax(self.model.predict(testX), axis=1)\n",
    "        testY = np.array(testY)\n",
    "        print(\"Predicting... \")\n",
    "        print(testY)\n",
    "    def test_pic(self, pic):\n",
    "        testX = pic\n",
    "        testX = np.array(testX)\n",
    "        testY = np.argmax(self.model.predict(testX), axis=1)\n",
    "        testY = np.array(testY)\n",
    "        print(\"Predicting... \")\n",
    "        print(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 28, 12, 32)        2432      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 14, 6, 32)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 10, 2, 32)         25632     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 1, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 160)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               82432     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                16416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 126,912\n",
      "Trainable params: 126,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 1s 32ms/step - loss: 11.2989 - acc: 0.0860 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 2.7790 - acc: 0.2389 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 2.4564 - acc: 0.3394 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 2.0918 - acc: 0.4190 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.5917 - acc: 0.5285 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 1.3881 - acc: 0.5855 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1986 - acc: 0.6281 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.1354 - acc: 0.6633 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8442 - acc: 0.7186 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.7567 - acc: 0.7674 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7514 - acc: 0.7683 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6239 - acc: 0.7928 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5580 - acc: 0.8208 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5435 - acc: 0.8154 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5024 - acc: 0.8380 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5016 - acc: 0.8416 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3543 - acc: 0.8833 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4129 - acc: 0.8787 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3631 - acc: 0.8805 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.3416 - acc: 0.8751\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3416 - acc: 0.8751 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2525 - acc: 0.9149 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1914 - acc: 0.9222 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2544 - acc: 0.9158 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2165 - acc: 0.9213 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1988 - acc: 0.9285 - lr: 5.0000e-04\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2050 - acc: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1997 - acc: 0.9339 - lr: 5.0000e-04\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1984 - acc: 0.9312 - lr: 5.0000e-04\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2189 - acc: 0.9231 - lr: 5.0000e-04\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1779 - acc: 0.9294\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1779 - acc: 0.9294 - lr: 5.0000e-04\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1654 - acc: 0.9421 - lr: 2.5000e-04\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1404 - acc: 0.9430 - lr: 2.5000e-04\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1685 - acc: 0.9339 - lr: 2.5000e-04\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1391 - acc: 0.9484 - lr: 2.5000e-04\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.1376 - acc: 0.9475 - lr: 2.5000e-04\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1624 - acc: 0.9475 - lr: 2.5000e-04\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1393 - acc: 0.9538 - lr: 2.5000e-04\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1582 - acc: 0.9466 - lr: 2.5000e-04\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1441 - acc: 0.9502 - lr: 2.5000e-04\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1278 - acc: 0.9529\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1278 - acc: 0.9529 - lr: 2.5000e-04\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1110 - acc: 0.9548 - lr: 1.2500e-04\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1324 - acc: 0.9511 - lr: 1.2500e-04\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1355 - acc: 0.9493 - lr: 1.2500e-04\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1059 - acc: 0.9566 - lr: 1.2500e-04\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1177 - acc: 0.9502 - lr: 1.2500e-04\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1294 - acc: 0.9511 - lr: 1.2500e-04\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1031 - acc: 0.9602 - lr: 1.2500e-04\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.1163 - acc: 0.9566 - lr: 1.2500e-04\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1095 - acc: 0.9575 - lr: 1.2500e-04\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1143 - acc: 0.9584\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1143 - acc: 0.9584 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1931/1931 [==============================] - 5s 2ms/step\n",
      "Predicting... \n",
      "[ 8 28  3 ...  2  5  8]\n"
     ]
    }
   ],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFDUlEQVR4nO3d0XHbRhRAUSKTPlIE3H8FVhH5Tw9IAxRAarkmLnHODH8sUyBB3YFHz7tYtm27Aef317tfAPAYsUKEWCFCrBAhVogQK0T8/cxfXpblknOedV13v/719TXt+aPHHrV3/NFjH723PbPf9ztt27bc+/PlmTnrVWM9OkfLcvfcvuT5o8cetXf80WOPzPhnv+93+i5W/wyGCLFChFghQqwQIVaIeGp0c1Xl3zyO/jZ55m+qZ57X0dVkZ/zMXVkhQqwQIVaIECtEiBUixAoRYoUIq24eMHvVDfedcdb5J1h1A3FihQixQoRYIUKsECFWiLBE7gFGM3PMPK8zN7F7F1dWiBArRIgVIsQKEWKFCLFChFghwpz1Aeao53PGOehsrqwQIVaIECtEiBUixAoRYoUIsUKEOesDrGedY2RN6ZlvNzmLKytEiBUixAoRYoUIsUKEWCFCrBBhzvoAc9T3mHne7RsMTCNWiBArRIgVIsQKEWKFCKMbTmtkfFIczRxxZYUIsUKEWCFCrBAhVogQK0SIFSKeinVd19u2bT9+nFX1dX+6kZ+1ZVl2H0WurBAhVogQK0SIFSLEChFihQixQsTyzBxxWZahoePesd45+zJL7Rn9eTnzetdt2+4e3JUVIsQKEWKFCLFChFghQqwQIVaIeOl61nf6xHW2fO+Kn6krK0SIFSLEChFihQixQoRYIUKsEPHS+7OOrBEcXV949PVPnb0dcV4+hysrRIgVIsQKEWKFCLFChFgh4jRbkT5w7Gnfm+s5820fbUUKcWKFCLFChFghQqwQIVaIECtEnGYr0mVZdh9X3HryFY7O61UVf55cWSFCrBAhVogQK0SIFSLEChFihYiXrmcd3U50xFlnY6NG1/FaB3zfmWfM1rNCnFghQqwQIVaIECtEiBUixAoRL73l48js6qrzvne76hz2nf8n4KdcWSFCrBAhVogQK0SIFSLEChFihYjT7BvMz4zuC3y0f649h+8b6WDvueu6fvs8V1aIECtEiBUixAoRYoUIsULES7ciPWK8Q8XI0sHRsZatSCFOrBAhVogQK0SIFSLEChFihYg/ukTOcisqRpYOHj3XEjn4cGKFCLFChFghQqwQIVaIECtEvPSWj0esZ+UKZt1G05UVIsQKEWKFCLFChFghQqwQIVaI+KP7Bu8xg+UqHpjD2jcYysQKEWKFCLFChFghQqwQYYkcvNisrXVdWSFCrBAhVogQK0SIFSLEChFihYiXzlnNUe8bmbsdndPRmd7IZzZry81Pt3defv369e3XXFkhQqwQIVaIECtEiBUixAoRYoWIp+as67refv/+Peu1ZI3OG/eeP3uO+s4Z8KfOYWedc1dWiBArRIgVIsQKEWKFCLFChFgh4qk569fX1+6M6FPnZmWz9rDl56xnhQ8nVogQK0SIFSLEChFihQixQsRTsa7retu27dvHVe2dk23bbsuy7D5Gvvc739vR+3r3a/80rqwQIVaIECtEiBUixAoRYoWIl97ycea2ljOPfWT2bRdnfu/R1z5y/JlbtF6RKytEiBUixAoRYoUIsUKEWCFCrBDx0q1Ij4zMUt85szvzrQtnzklvt7nvbeS8nvkzGWErUvgAYoUIsUKEWCFCrBAhVogQK0Q8u571v9vt9u9PD3bmdZ/VY89WPa/hz+Sf776wVIfHcDX+GQwRYoUIsUKEWCFCrBAhVogQK0SIFSLEChH/A4T0UhppKHN0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_scale = MAX_HEIGHT/1000\n",
    "w_scale = MAX_WIDTH/1000\n",
    "img = []\n",
    "resized_image = cv2.imread('class_A_3.jpg')\n",
    "img.append(resized_image)\n",
    "#resized_image = cv2.resize(resized_image, (12, 28))\n",
    "#print(resized_image)\n",
    "#img.extend([resized_image]) \n",
    "img = np.array(img, dtype = 'float32')\n",
    "#img = np.asarray(img, dtype = np.float64, \n",
    "#                        order ='C')\n",
    "display_image(img)\n",
    "#model.test_pic(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
